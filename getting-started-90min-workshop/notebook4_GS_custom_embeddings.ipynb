{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a029f92a",
   "metadata": {},
   "source": [
    "\n",
    "# FiftyOne Workshop: Custom Embeddings for Anomaly Detection (March 12th 2025)\n",
    "\n",
    "In this notebook, we will explore how to generate **custom embeddings** for **anomaly detection** using the **Padim model** from Anomalib. \n",
    "Unlike general-purpose embeddings from models like CLIP or ResNet, anomaly detection requires **task-specific embeddings** that can distinguish between normal and abnormal samples.\n",
    "\n",
    "![Image](https://github.com/user-attachments/assets/f62e79c2-e031-4320-8a2d-98dd03161d98)\n",
    "\n",
    "## üèÜ Learning Objectives:\n",
    "- Understand the difference between standard embeddings and anomaly-specific embeddings.\n",
    "- Explore how to compute embeddings using **Padim from Anomalib**.\n",
    "- Integrate these embeddings into a FiftyOne dataset.\n",
    "- Leverage FiftyOne for visualization and analysis.\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "196000c7",
   "metadata": {},
   "source": [
    "\n",
    "## üìå Why Use Custom Embeddings for Anomaly Detection?\n",
    "\n",
    "Pre-trained models like **CLIP or ResNet** generate **general-purpose embeddings** that focus on visual similarity. However, detecting **abnormalities** requires learning **subtle deviations** from normal patterns, which these models cannot capture effectively.\n",
    "\n",
    "Instead, we use a dedicated anomaly detection model like **Padim from Anomalib**, which:\n",
    "- Learns representations specific to normal and anomalous samples.\n",
    "- Extracts feature maps from an encoder (e.g., ResNet).\n",
    "- Compares new samples against normal feature distributions.\n",
    "\n",
    "### üîó Further Reading:\n",
    "- [Anomalib Documentation](https://github.com/openvinotoolkit/anomalib)\n",
    "- [Understanding Memory-Based Anomaly Detection](https://arxiv.org/pdf/2011.08785)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the MVTec Dataset as usual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading config file fiftyone.yml from Voxel51/mvtec-ad\n",
      "Loading dataset\n",
      "Importing samples...\n",
      " 100% |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 5354/5354 [68.5ms elapsed, 0s remaining, 78.2K samples/s]   \n",
      "Migrating dataset 'Voxel51/mvtec-ad' to v1.3.0\n",
      "Dataset 'mvtec-ad_4' does not exist. Creating a new one...\n"
     ]
    }
   ],
   "source": [
    "import fiftyone as fo\n",
    "import fiftyone.utils.huggingface as fouh # Hugging Face integration\n",
    "\n",
    "# Load dataset\n",
    "# Load the dataset\n",
    "dataset_ = fouh.load_from_hub(\"Voxel51/mvtec-ad\", persistent=True, overwrite=True)\n",
    "#dataset = fo.load_dataset(\"Voxel51/mvtec-ad\") # Use this CLI if you already have the dataset \n",
    "                                               # in your disk or if this is not the first time you run this notebook \n",
    "\n",
    "# Define the new dataset name\n",
    "dataset_name = \"mvtec-ad_4\"\n",
    "\n",
    "# Check if the dataset exists\n",
    "if dataset_name in fo.list_datasets():\n",
    "    print(f\"Dataset '{dataset_name}' exists. Loading...\")\n",
    "    dataset = fo.load_dataset(dataset_name)\n",
    "else:\n",
    "    print(f\"Dataset '{dataset_name}' does not exist. Creating a new one...\")\n",
    "    # Clone the dataset with a new name and make it persistent\n",
    "    dataset = dataset_.clone(dataset_name, persistent=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af37356c",
   "metadata": {},
   "source": [
    "\n",
    "## üöÄ Extracting Custom Embeddings from Padim (Anomalib)\n",
    "\n",
    "Instead of using a general embedding model, we will:\n",
    "1. **Load a Padim anomaly detection model** using Anomalib.\n",
    "2. **Run inference on a dataset** to extract anomaly embeddings.\n",
    "3. **Store the embeddings in FiftyOne** for further visualization.\n",
    "\n",
    "üîó **Relevant Documentation:**  \n",
    "- [Anomalib Models](https://anomalib.readthedocs.io/en/latest/markdown/guides/reference/models/image/index.html)  \n",
    "- [Remotely-sourced Zoo Models](https://docs.voxel51.com/model_zoo/remote.html)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<frozen importlib.util>:262: DeprecationWarning: The `openvino.runtime` module is deprecated and will be removed in the 2026.0 release. Please replace `openvino.runtime` with `openvino`.\n",
      "/Users/paularamos/Documents/fiftyone_CVPR/py311_anomalib200b3/lib/python3.11/site-packages/timm/models/layers/__init__.py:48: FutureWarning: Importing from timm.models.layers is deprecated, please import via timm.layers\n",
      "  warnings.warn(f\"Importing from {__name__} is deprecated, please import via timm.layers\", FutureWarning)\n",
      "INFO:timm.models._builder:Loading pretrained weights from Hugging Face hub (timm/resnet18.a1_in1k)\n",
      "INFO:timm.models._hub:[timm/resnet18.a1_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.\n",
      "INFO:timm.models._builder:Missing keys (fc.weight, fc.bias) discovered while loading pretrained weights. This is expected if model is being adapted.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "PadimModel(\n",
       "  (feature_extractor): TimmFeatureExtractor(\n",
       "    (feature_extractor): FeatureListNet(\n",
       "      (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (act1): ReLU(inplace=True)\n",
       "      (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "      (layer1): Sequential(\n",
       "        (0): BasicBlock(\n",
       "          (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (drop_block): Identity()\n",
       "          (act1): ReLU(inplace=True)\n",
       "          (aa): Identity()\n",
       "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (act2): ReLU(inplace=True)\n",
       "        )\n",
       "        (1): BasicBlock(\n",
       "          (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (drop_block): Identity()\n",
       "          (act1): ReLU(inplace=True)\n",
       "          (aa): Identity()\n",
       "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (act2): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "      (layer2): Sequential(\n",
       "        (0): BasicBlock(\n",
       "          (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (drop_block): Identity()\n",
       "          (act1): ReLU(inplace=True)\n",
       "          (aa): Identity()\n",
       "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (act2): ReLU(inplace=True)\n",
       "          (downsample): Sequential(\n",
       "            (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "            (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (1): BasicBlock(\n",
       "          (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (drop_block): Identity()\n",
       "          (act1): ReLU(inplace=True)\n",
       "          (aa): Identity()\n",
       "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (act2): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (anomaly_map_generator): AnomalyMapGenerator(\n",
       "    (blur): GaussianBlur2d()\n",
       "  )\n",
       "  (gaussian): MultiVariateGaussian()\n",
       ")"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from anomalib.models.image.padim.torch_model import PadimModel\n",
    "\n",
    "# Create a PaDiM model\n",
    "model = PadimModel(\n",
    "    backbone=\"resnet18\",           # or \"wide_resnet50_2\", etc.\n",
    "    layers=[\"layer1\", \"layer2\"],   # choose the layers you want\n",
    "    pre_trained=True,\n",
    "    n_features=100                 # optional dimension reduction\n",
    ")\n",
    "model.eval()  # set to eval mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PadimModel(\n",
      "  (feature_extractor): TimmFeatureExtractor(\n",
      "    (feature_extractor): FeatureListNet(\n",
      "      (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (act1): ReLU(inplace=True)\n",
      "      (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "      (layer1): Sequential(\n",
      "        (0): BasicBlock(\n",
      "          (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (drop_block): Identity()\n",
      "          (act1): ReLU(inplace=True)\n",
      "          (aa): Identity()\n",
      "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (act2): ReLU(inplace=True)\n",
      "        )\n",
      "        (1): BasicBlock(\n",
      "          (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (drop_block): Identity()\n",
      "          (act1): ReLU(inplace=True)\n",
      "          (aa): Identity()\n",
      "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (act2): ReLU(inplace=True)\n",
      "        )\n",
      "      )\n",
      "      (layer2): Sequential(\n",
      "        (0): BasicBlock(\n",
      "          (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (drop_block): Identity()\n",
      "          (act1): ReLU(inplace=True)\n",
      "          (aa): Identity()\n",
      "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (act2): ReLU(inplace=True)\n",
      "          (downsample): Sequential(\n",
      "            (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "            (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          )\n",
      "        )\n",
      "        (1): BasicBlock(\n",
      "          (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (drop_block): Identity()\n",
      "          (act1): ReLU(inplace=True)\n",
      "          (aa): Identity()\n",
      "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (act2): ReLU(inplace=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (anomaly_map_generator): AnomalyMapGenerator(\n",
      "    (blur): GaussianBlur2d()\n",
      "  )\n",
      "  (gaussian): MultiVariateGaussian()\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:anomalib.models.components.base.anomalib_module:Initializing Padim model.\n",
      "INFO:timm.models._builder:Loading pretrained weights from Hugging Face hub (timm/resnet18.a1_in1k)\n",
      "INFO:timm.models._hub:[timm/resnet18.a1_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.\n",
      "INFO:timm.models._builder:Missing keys (fc.weight, fc.bias) discovered while loading pretrained weights. This is expected if model is being adapted.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 100, 56, 56])\n"
     ]
    }
   ],
   "source": [
    "from anomalib.models.image.padim.lightning_model import Padim\n",
    "import torch\n",
    "from PIL import Image\n",
    "import torchvision.transforms as T\n",
    "\n",
    "# 1) Create the Lightning-based PaDiM\n",
    "padim = Padim(\n",
    "    backbone=\"resnet18\",\n",
    "    layers=[\"layer1\", \"layer2\"],\n",
    "    pre_trained=True\n",
    ")\n",
    "padim.train()  # so forward(...) returns embeddings\n",
    "\n",
    "# 2) Load image\n",
    "transform = T.Compose([T.Resize(224), T.ToTensor()])\n",
    "pil_image = Image.open(\"/Users/paularamos/fiftyone/huggingface/hub/Voxel51/mvtec-ad/data/data_50/018-57.png\").convert(\"RGB\")\n",
    "tensor = transform(pil_image).unsqueeze(0)  # (1, C, H, W)\n",
    "\n",
    "# 3) Pass it through the model in train mode\n",
    "with torch.no_grad():\n",
    "    embeddings = padim.model(tensor)  # shape (1, embed_dim, H', W')\n",
    "print(embeddings.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "081dd2f4",
   "metadata": {},
   "source": [
    "\n",
    "## üîç Integrating Anomaly Embeddings into FiftyOne\n",
    "\n",
    "Once we obtain embeddings from Padim, we will add them to our FiftyOne dataset.\n",
    "This allows us to:\n",
    "- Perform **similarity searches** based on anomaly scores.\n",
    "- Compare normal vs. abnormal sample distributions.\n",
    "- Leverage **FiftyOne App** to inspect anomalies.\n",
    "\n",
    "```python\n",
    "import fiftyone as fo\n",
    "\n",
    "dataset = fo.Dataset(\"object_from_mvtec_ad\")\n",
    "\n",
    "# Add embeddings to each sample\n",
    "for sample in dataset:\n",
    "    ...\n",
    "    # Convert to CPU NumPy for storage\n",
    "    embedding_1d = patch_embedding.squeeze(0).cpu().numpy()  # shape (D,)\n",
    "\n",
    "    # Store as a list in a new field\n",
    "    sample[\"embedding\"] = embedding_1d.tolist()\n",
    "    sample.save()\n",
    "    ...\n",
    "```\n",
    "üîó **Relevant Documentation:** [Adding Custom Fields to FiftyOne Datasets](https://docs.voxel51.com/user_guide/using_datasets.html)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Selecting object from MVTec AD Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name:        mvtec-bottle\n",
      "Media type:  image\n",
      "Num samples: 292\n",
      "Persistent:  True\n",
      "Tags:        []\n",
      "Sample fields:\n",
      "    id:               fiftyone.core.fields.ObjectIdField\n",
      "    filepath:         fiftyone.core.fields.StringField\n",
      "    tags:             fiftyone.core.fields.ListField(fiftyone.core.fields.StringField)\n",
      "    metadata:         fiftyone.core.fields.EmbeddedDocumentField(fiftyone.core.metadata.ImageMetadata)\n",
      "    created_at:       fiftyone.core.fields.DateTimeField\n",
      "    last_modified_at: fiftyone.core.fields.DateTimeField\n",
      "    category:         fiftyone.core.fields.EmbeddedDocumentField(fiftyone.core.labels.Classification)\n",
      "    defect:           fiftyone.core.fields.EmbeddedDocumentField(fiftyone.core.labels.Classification)\n",
      "    split:            fiftyone.core.fields.StringField\n",
      "    defect_mask:      fiftyone.core.fields.EmbeddedDocumentField(fiftyone.core.labels.Segmentation)\n"
     ]
    }
   ],
   "source": [
    "from fiftyone import ViewField as F # helper for defining views\n",
    "\n",
    "## get the test split of the dataset\n",
    "test_split = dataset.match(F(\"category.label\") == 'bottle')\n",
    "\n",
    "# Clone the dataset into a new one called \"mvtec_bottle\"\n",
    "mvtec_bottle = test_split.clone(\"mvtec-bottle\", persistent=True)\n",
    "\n",
    "print(mvtec_bottle)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name:        mvtec-ad_4\n",
      "Media type:  image\n",
      "Num samples: 5354\n",
      "Persistent:  True\n",
      "Tags:        []\n",
      "Sample fields:\n",
      "    id:               fiftyone.core.fields.ObjectIdField\n",
      "    filepath:         fiftyone.core.fields.StringField\n",
      "    tags:             fiftyone.core.fields.ListField(fiftyone.core.fields.StringField)\n",
      "    metadata:         fiftyone.core.fields.EmbeddedDocumentField(fiftyone.core.metadata.ImageMetadata)\n",
      "    created_at:       fiftyone.core.fields.DateTimeField\n",
      "    last_modified_at: fiftyone.core.fields.DateTimeField\n",
      "    category:         fiftyone.core.fields.EmbeddedDocumentField(fiftyone.core.labels.Classification)\n",
      "    defect:           fiftyone.core.fields.EmbeddedDocumentField(fiftyone.core.labels.Classification)\n",
      "    split:            fiftyone.core.fields.StringField\n",
      "    defect_mask:      fiftyone.core.fields.EmbeddedDocumentField(fiftyone.core.labels.Segmentation)\n",
      "Name:        mvtec-bottle\n",
      "Media type:  image\n",
      "Num samples: 292\n",
      "Persistent:  True\n",
      "Tags:        []\n",
      "Sample fields:\n",
      "    id:               fiftyone.core.fields.ObjectIdField\n",
      "    filepath:         fiftyone.core.fields.StringField\n",
      "    tags:             fiftyone.core.fields.ListField(fiftyone.core.fields.StringField)\n",
      "    metadata:         fiftyone.core.fields.EmbeddedDocumentField(fiftyone.core.metadata.ImageMetadata)\n",
      "    created_at:       fiftyone.core.fields.DateTimeField\n",
      "    last_modified_at: fiftyone.core.fields.DateTimeField\n",
      "    category:         fiftyone.core.fields.EmbeddedDocumentField(fiftyone.core.labels.Classification)\n",
      "    defect:           fiftyone.core.fields.EmbeddedDocumentField(fiftyone.core.labels.Classification)\n",
      "    split:            fiftyone.core.fields.StringField\n",
      "    defect_mask:      fiftyone.core.fields.EmbeddedDocumentField(fiftyone.core.labels.Segmentation)\n"
     ]
    }
   ],
   "source": [
    "print(dataset)\n",
    "print(mvtec_bottle)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculating Embeddings using Inference with Padim Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from PIL import Image\n",
    "\n",
    "for sample in mvtec_bottle:\n",
    "    # Load the image via PIL\n",
    "    pil_image = Image.open(sample.filepath).convert(\"RGB\")\n",
    "\n",
    "    # Apply your transform\n",
    "    input_tensor = transform(pil_image).unsqueeze(0)  # shape (1, C, H, W)\n",
    "\n",
    "    # Compute patch embeddings in train mode\n",
    "    with torch.no_grad():\n",
    "        patch_embedding = padim.model(input_tensor)  # shape (1, D, H', W')\n",
    "\n",
    "    # Optional: flatten or pool across spatial dims\n",
    "    # Here we use mean pooling to get a (1, D) vector\n",
    "    patch_embedding = patch_embedding.mean(dim=[2, 3])  # shape (1, D)\n",
    "\n",
    "    # Convert to CPU NumPy for storage\n",
    "    embedding_1d = patch_embedding.squeeze(0).cpu().numpy()  # shape (D,)\n",
    "\n",
    "    # Store as a list in a new field\n",
    "    sample[\"embedding\"] = embedding_1d.tolist()\n",
    "    sample.save()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualizing Embeddings in FiftyOne"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing embeddings...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:fiftyone.brain.internal.core.utils:Computing embeddings...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 100% |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 292/292 [46.6s elapsed, 0s remaining, 6.2 samples/s]      \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:eta.core.utils: 100% |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 292/292 [46.6s elapsed, 0s remaining, 6.2 samples/s]      \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating visualization...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:fiftyone.brain.visualization:Generating visualization...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<fiftyone.brain.visualization.VisualizationResults at 0x34e26fd90>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from fiftyone.brain import compute_visualization\n",
    "\n",
    "# This will perform PCA on the \"embedding\" field\n",
    "compute_visualization(\n",
    "    mvtec_bottle,\n",
    "    embeddings=\"padin_emb\",\n",
    "    brain_key=\"embedding_pca\",\n",
    "    method=\"pca\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name:        mvtec-bottle\n",
      "Media type:  image\n",
      "Num samples: 292\n",
      "Persistent:  True\n",
      "Tags:        []\n",
      "Sample fields:\n",
      "    id:               fiftyone.core.fields.ObjectIdField\n",
      "    filepath:         fiftyone.core.fields.StringField\n",
      "    tags:             fiftyone.core.fields.ListField(fiftyone.core.fields.StringField)\n",
      "    metadata:         fiftyone.core.fields.EmbeddedDocumentField(fiftyone.core.metadata.ImageMetadata)\n",
      "    created_at:       fiftyone.core.fields.DateTimeField\n",
      "    last_modified_at: fiftyone.core.fields.DateTimeField\n",
      "    category:         fiftyone.core.fields.EmbeddedDocumentField(fiftyone.core.labels.Classification)\n",
      "    defect:           fiftyone.core.fields.EmbeddedDocumentField(fiftyone.core.labels.Classification)\n",
      "    split:            fiftyone.core.fields.StringField\n",
      "    defect_mask:      fiftyone.core.fields.EmbeddedDocumentField(fiftyone.core.labels.Segmentation)\n",
      "    embedding:        fiftyone.core.fields.ListField(fiftyone.core.fields.FloatField)\n",
      "    padin_emb:        fiftyone.core.fields.VectorField\n",
      "<Sample: {\n",
      "    'id': '6621d76a324f6e05d5838da1',\n",
      "    'media_type': 'image',\n",
      "    'filepath': '/Users/paularamos/fiftyone/huggingface/hub/Voxel51/mvtec-ad/data/data_50/018-57.png',\n",
      "    'tags': [],\n",
      "    'metadata': None,\n",
      "    'created_at': datetime.datetime(2025, 3, 5, 23, 1, 11, 730000),\n",
      "    'last_modified_at': datetime.datetime(2025, 3, 5, 23, 2, 48, 284000),\n",
      "    'category': <Classification: {\n",
      "        'id': '6621d769324f6e05d5837726',\n",
      "        'tags': [],\n",
      "        'label': 'bottle',\n",
      "        'confidence': None,\n",
      "        'logits': None,\n",
      "    }>,\n",
      "    'defect': <Classification: {\n",
      "        'id': '6621d769324f6e05d5837727',\n",
      "        'tags': [],\n",
      "        'label': 'contamination',\n",
      "        'confidence': None,\n",
      "        'logits': None,\n",
      "    }>,\n",
      "    'split': 'test',\n",
      "    'defect_mask': <Segmentation: {\n",
      "        'id': '6621d769324f6e05d5837728',\n",
      "        'tags': [],\n",
      "        'mask': None,\n",
      "        'mask_path': '/Users/paularamos/fiftyone/huggingface/hub/Voxel51/mvtec-ad/fields/defect_mask/defect_mask_12/018_mask-30.png',\n",
      "    }>,\n",
      "    'embedding': [\n",
      "        0.7578526139259338,\n",
      "        0.4961361885070801,\n",
      "        0.22806569933891296,\n",
      "        0.2753605842590332,\n",
      "        4.099868297576904,\n",
      "        1.0455999374389648,\n",
      "        1.6506954431533813,\n",
      "        0.8169431090354919,\n",
      "        0.5272068381309509,\n",
      "        0.7614158987998962,\n",
      "        0.6898508667945862,\n",
      "        0.6502408385276794,\n",
      "        0.47233137488365173,\n",
      "        0.5288400650024414,\n",
      "        4.147706985473633,\n",
      "        1.3612945079803467,\n",
      "        0.2624938189983368,\n",
      "        0.7061997056007385,\n",
      "        0.3978869318962097,\n",
      "        0.7186100482940674,\n",
      "        0.7975745797157288,\n",
      "        2.7627692222595215,\n",
      "        2.6010823249816895,\n",
      "        2.901385545730591,\n",
      "        1.317185640335083,\n",
      "        1.2795546054840088,\n",
      "        0.7013506293296814,\n",
      "        1.7068805694580078,\n",
      "        0.3142932951450348,\n",
      "        1.2184785604476929,\n",
      "        0.7232950329780579,\n",
      "        4.461272716522217,\n",
      "        3.086787223815918,\n",
      "        5.682888031005859,\n",
      "        1.4719442129135132,\n",
      "        1.3977752923965454,\n",
      "        0.70331871509552,\n",
      "        2.076085329055786,\n",
      "        8.666643142700195,\n",
      "        1.5889629125595093,\n",
      "        4.292508602142334,\n",
      "        3.4366960525512695,\n",
      "        4.248833656311035,\n",
      "        1.1775906085968018,\n",
      "        1.0853208303451538,\n",
      "        1.5944992303848267,\n",
      "        0.7427877187728882,\n",
      "        1.4033713340759277,\n",
      "        2.386178970336914,\n",
      "        1.7686262130737305,\n",
      "        2.5296852588653564,\n",
      "        1.0285946130752563,\n",
      "        0.7324624061584473,\n",
      "        0.41251909732818604,\n",
      "        3.731541872024536,\n",
      "        7.881486415863037,\n",
      "        3.5675272941589355,\n",
      "        0.001496333978138864,\n",
      "        0.2456447035074234,\n",
      "        2.172899007797241,\n",
      "        0.9891461730003357,\n",
      "        1.0269975662231445,\n",
      "        0.8717805743217468,\n",
      "        0.49973535537719727,\n",
      "        0.4033398926258087,\n",
      "        1.6542606353759766,\n",
      "        3.7425427436828613,\n",
      "        0.47301435470581055,\n",
      "        0.19858889281749725,\n",
      "        1.0339356660842896,\n",
      "        4.138635158538818,\n",
      "        0.7035189867019653,\n",
      "        0.8355362415313721,\n",
      "        2.1063830852508545,\n",
      "        0.23427560925483704,\n",
      "        1.830406665802002,\n",
      "        3.1286213397979736,\n",
      "        2.8700568675994873,\n",
      "        1.0486626625061035,\n",
      "        0.9771326184272766,\n",
      "        0.07206553220748901,\n",
      "        1.2635579109191895,\n",
      "        0.927085280418396,\n",
      "        2.5889008045196533,\n",
      "        2.1695618629455566,\n",
      "        0.48822328448295593,\n",
      "        1.0934605598449707,\n",
      "        1.034006118774414,\n",
      "        2.4138550758361816,\n",
      "        3.5346035957336426,\n",
      "        1.003427505493164,\n",
      "        0.9629521369934082,\n",
      "        0.2698665261268616,\n",
      "        0.4934004843235016,\n",
      "        0.3752824068069458,\n",
      "        3.1572937965393066,\n",
      "        1.1436127424240112,\n",
      "        0.804200291633606,\n",
      "        0.28505390882492065,\n",
      "        0.169851616024971,\n",
      "    ],\n",
      "    'padin_emb': array([0.00427041, 0.        , 0.0086558 , ..., 0.0211228 , 0.00234637,\n",
      "           0.00728599]),\n",
      "}>\n"
     ]
    }
   ],
   "source": [
    "mvtec_bottle.reload()\n",
    "print(mvtec_bottle)\n",
    "print(mvtec_bottle.last())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/paularamos/Documents/fiftyone_CVPR/py311_anomalib200b3/lib/python3.11/site-packages/fiftyone/service/util.py:114: DeprecationWarning: connections() is deprecated and will be removed; use net_connections() instead\n",
      "  for conn in process.connections(kind=\"tcp\"):\n",
      "/Users/paularamos/Documents/fiftyone_CVPR/py311_anomalib200b3/lib/python3.11/site-packages/fiftyone/service/util.py:114: DeprecationWarning: connections() is deprecated and will be removed; use net_connections() instead\n",
      "  for conn in process.connections(kind=\"tcp\"):\n",
      "/Users/paularamos/Documents/fiftyone_CVPR/py311_anomalib200b3/lib/python3.11/site-packages/fiftyone/service/util.py:114: DeprecationWarning: connections() is deprecated and will be removed; use net_connections() instead\n",
      "  for conn in process.connections(kind=\"tcp\"):\n",
      "/Users/paularamos/Documents/fiftyone_CVPR/py311_anomalib200b3/lib/python3.11/site-packages/fiftyone/service/util.py:114: DeprecationWarning: connections() is deprecated and will be removed; use net_connections() instead\n",
      "  for conn in process.connections(kind=\"tcp\"):\n",
      "/Users/paularamos/Documents/fiftyone_CVPR/py311_anomalib200b3/lib/python3.11/site-packages/fiftyone/service/util.py:114: DeprecationWarning: connections() is deprecated and will be removed; use net_connections() instead\n",
      "  for conn in process.connections(kind=\"tcp\"):\n",
      "/Users/paularamos/Documents/fiftyone_CVPR/py311_anomalib200b3/lib/python3.11/site-packages/fiftyone/service/util.py:114: DeprecationWarning: connections() is deprecated and will be removed; use net_connections() instead\n",
      "  for conn in process.connections(kind=\"tcp\"):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Session launched. Run `session.show()` to open the App in a cell output.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/paularamos/Documents/fiftyone_CVPR/py311_anomalib200b3/lib/python3.11/site-packages/fiftyone/service/util.py:114: DeprecationWarning: connections() is deprecated and will be removed; use net_connections() instead\n",
      "  for conn in process.connections(kind=\"tcp\"):\n",
      "INFO:fiftyone.core.session.session:Session launched. Run `session.show()` to open the App in a cell output.\n"
     ]
    }
   ],
   "source": [
    "session = fo.launch_app(mvtec_bottle, port=5154, auto=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Image](https://github.com/user-attachments/assets/09338015-ed1d-49ae-820a-9065b8965bae)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "428fe1d7",
   "metadata": {},
   "source": [
    "### Next Steps:\n",
    "Try using different anomaly detection models from Anomalib and compare their embeddings with FiftyOne's visualization tools! üöÄ\n",
    "\n",
    "üîó **More Resources:**  \n",
    "- [FiftyOne Docs](https://voxel51.com/docs/fiftyone/)  \n",
    "- [Anomalib GitHub Repository](https://github.com/openvinotoolkit/anomalib)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py311_anomalib200b3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
